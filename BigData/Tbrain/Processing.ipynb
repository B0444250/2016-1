{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Steps\n",
    "---\n",
    "1. Features Engineering\n",
    "- parameters of Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cch/anaconda36/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib,os\n",
    "from stockstats import StockDataFrame as Sdf\n",
    "# load Lasso\n",
    "from sklearn.linear_model import  Lasso ,MultiTaskElasticNet\n",
    "# load NN functions\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "from xgboost import XGBRegressor,plot_importance\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0050_date=pd.read_csv(\"yahoo/20180511/0050.csv\",index_col='Date') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>weekday</th>\n",
       "      <th>code</th>\n",
       "      <th>yesterday_close</th>\n",
       "      <th>yesterday_volume</th>\n",
       "      <th>price_change</th>\n",
       "      <th>volume_Change</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>80.70</td>\n",
       "      <td>80.70</td>\n",
       "      <td>80.45</td>\n",
       "      <td>80.65</td>\n",
       "      <td>5977.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>80.45</td>\n",
       "      <td>3359.000000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2618.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11</th>\n",
       "      <td>81.10</td>\n",
       "      <td>81.70</td>\n",
       "      <td>81.05</td>\n",
       "      <td>81.60</td>\n",
       "      <td>17654.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>80.65</td>\n",
       "      <td>5977.000000</td>\n",
       "      <td>0.95</td>\n",
       "      <td>11677.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14</th>\n",
       "      <td>85.43</td>\n",
       "      <td>85.74</td>\n",
       "      <td>85.04</td>\n",
       "      <td>85.43</td>\n",
       "      <td>3059.522631</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>81.60</td>\n",
       "      <td>17654.000000</td>\n",
       "      <td>3.83</td>\n",
       "      <td>-14594.477369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-15</th>\n",
       "      <td>85.48</td>\n",
       "      <td>85.79</td>\n",
       "      <td>85.09</td>\n",
       "      <td>85.48</td>\n",
       "      <td>2822.583315</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>85.43</td>\n",
       "      <td>3059.522631</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-236.939317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-16</th>\n",
       "      <td>85.53</td>\n",
       "      <td>85.85</td>\n",
       "      <td>85.14</td>\n",
       "      <td>85.53</td>\n",
       "      <td>2803.552445</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>85.48</td>\n",
       "      <td>2822.583315</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-19.030870</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-17</th>\n",
       "      <td>85.58</td>\n",
       "      <td>85.90</td>\n",
       "      <td>85.20</td>\n",
       "      <td>85.58</td>\n",
       "      <td>2891.492010</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>85.53</td>\n",
       "      <td>2803.552445</td>\n",
       "      <td>0.05</td>\n",
       "      <td>87.939566</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-18</th>\n",
       "      <td>85.63</td>\n",
       "      <td>85.95</td>\n",
       "      <td>85.25</td>\n",
       "      <td>85.63</td>\n",
       "      <td>2957.947264</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>85.58</td>\n",
       "      <td>2891.492010</td>\n",
       "      <td>0.05</td>\n",
       "      <td>66.455254</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Open   High    Low  Close        Volume  weekday  code  \\\n",
       "Date                                                                  \n",
       "2018-05-10  80.70  80.70  80.45  80.65   5977.000000        3    50   \n",
       "2018-05-11  81.10  81.70  81.05  81.60  17654.000000        4    50   \n",
       "2018-05-14  85.43  85.74  85.04  85.43   3059.522631        0    50   \n",
       "2018-05-15  85.48  85.79  85.09  85.48   2822.583315        1    50   \n",
       "2018-05-16  85.53  85.85  85.14  85.53   2803.552445        2    50   \n",
       "2018-05-17  85.58  85.90  85.20  85.58   2891.492010        3    50   \n",
       "2018-05-18  85.63  85.95  85.25  85.63   2957.947264        4    50   \n",
       "\n",
       "            yesterday_close  yesterday_volume  price_change  volume_Change  \\\n",
       "Date                                                                         \n",
       "2018-05-10            80.45       3359.000000          0.20    2618.000000   \n",
       "2018-05-11            80.65       5977.000000          0.95   11677.000000   \n",
       "2018-05-14            81.60      17654.000000          3.83  -14594.477369   \n",
       "2018-05-15            85.43       3059.522631          0.05    -236.939317   \n",
       "2018-05-16            85.48       2822.583315          0.05     -19.030870   \n",
       "2018-05-17            85.53       2803.552445          0.05      87.939566   \n",
       "2018-05-18            85.58       2891.492010          0.05      66.455254   \n",
       "\n",
       "            sign  \n",
       "Date              \n",
       "2018-05-10     1  \n",
       "2018-05-11     1  \n",
       "2018-05-14     1  \n",
       "2018-05-15     1  \n",
       "2018-05-16     1  \n",
       "2018-05-17     1  \n",
       "2018-05-18     1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0050_date.tail(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0050_date_1=df0050_date.copy()\n",
    "stock_df = Sdf.retype(df0050_date_1)\n",
    "#df0050_date['rsi5']=stock_df['rsi_5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volatility\n",
    "---\n",
    "\n",
    "1. $\\mathbf{\\text{ret}_i= \\log x_i -\\log x_{i-1}}$\n",
    "-  Volatility=$\\mathbf{\\sum_w \\text{std}(\\text{ret}_i)/w}$, where $w$ is the length of considered period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(df):\n",
    "    \"\"\" Generate features for a stock/index based on historical price and performance\n",
    "    Args:\n",
    "        df (dataframe with columns \"Open\", \"Close\", \"High\", \"Low\", \"Volume\", \"Adjusted Close\")\n",
    "    Returns:\n",
    "        dataframe, data set with new features\n",
    "    \"\"\"\n",
    "    df_new = pd.DataFrame()\n",
    "    # 6 original features\n",
    "    df_new['High'] = df['High']\n",
    "    df_new['Low'] = df['Low']\n",
    "    df_new['weekday'] = df['weekday']\n",
    "    df_new['code'] = df['code']\n",
    "    #df_new['price_change'] = df['price_Change']\n",
    "    df_new['sign'] = df['sign']\n",
    "    \n",
    "    \n",
    "    df_new['Open'] = df['Open']\n",
    "    df_new['open_1'] = df['Open'].shift(1)\n",
    "    df_new['close_1'] = df['Close'].shift(1)\n",
    "    df_new['high_1'] = df['High'].shift(1)\n",
    "    df_new['low_1'] = df['Low'].shift(1)\n",
    "    df_new['volume_1'] = df['Volume'].shift(1)\n",
    "    # 31 original features\n",
    "    # average price\n",
    "    df_new['avg_price_5'] = pd.rolling_mean(df['Close'], window=5).shift(1)\n",
    "    df_new['avg_price_30'] = pd.rolling_mean(df['Close'], window=21).shift(1)\n",
    "    df_new['avg_price_365'] = pd.rolling_mean(df['Close'], window=252).shift(1)\n",
    "    df_new['ratio_avg_price_5_30'] = df_new['avg_price_5'] / df_new['avg_price_30']\n",
    "    df_new['ratio_avg_price_5_365'] = df_new['avg_price_5'] / df_new['avg_price_365']\n",
    "    df_new['ratio_avg_price_30_365'] = df_new['avg_price_30'] / df_new['avg_price_365']\n",
    "    # average volume\n",
    "    df_new['avg_volume_5'] = pd.rolling_mean(df['Volume'], window=5).shift(1)\n",
    "    df_new['avg_volume_30'] = pd.rolling_mean(df['Volume'], window=21).shift(1)\n",
    "    df_new['avg_volume_365'] = pd.rolling_mean(df['Volume'], window=252).shift(1)\n",
    "    df_new['ratio_avg_volume_5_30'] = df_new['avg_volume_5'] / df_new['avg_volume_30']\n",
    "    df_new['ratio_avg_volume_5_365'] = df_new['avg_volume_5'] / df_new['avg_volume_365']\n",
    "    df_new['ratio_avg_volume_30_365'] = df_new['avg_volume_30'] / df_new['avg_volume_365']\n",
    "    # standard deviation of prices\n",
    "    df_new['std_price_5'] = pd.rolling_std(df['Close'], window=5).shift(1)\n",
    "    df_new['std_price_30'] = pd.rolling_std(df['Close'], window=21).shift(1)\n",
    "    df_new['std_price_365'] = pd.rolling_std(df['Close'], window=252).shift(1)\n",
    "    df_new['ratio_std_price_5_30'] = df_new['std_price_5'] / df_new['std_price_30']\n",
    "    df_new['ratio_std_price_5_365'] = df_new['std_price_5'] / df_new['std_price_365']\n",
    "    df_new['ratio_std_price_30_365'] = df_new['std_price_30'] / df_new['std_price_365']\n",
    "    # standard deviation of volumes\n",
    "    df_new['std_volume_5'] = pd.rolling_std(df['Volume'], window=5).shift(1)\n",
    "    df_new['std_volume_30'] = pd.rolling_std(df['Volume'], window=21).shift(1)\n",
    "    df_new['std_volume_365'] = pd.rolling_std(df['Volume'], window=252).shift(1)\n",
    "    df_new['ratio_std_volume_5_30'] = df_new['std_volume_5'] / df_new['std_volume_30']\n",
    "    df_new['ratio_std_volume_5_365'] = df_new['std_volume_5'] / df_new['std_volume_365']\n",
    "    df_new['ratio_std_volume_30_365'] = df_new['std_volume_30'] / df_new['std_volume_365']\n",
    "    # # return\n",
    "    df_new['return_1'] = ((df['Close'] - df['Close'].shift(1)) / df['Close'].shift(1)).shift(1)\n",
    "    df_new['return_5'] = ((df['Close'] - df['Close'].shift(5)) / df['Close'].shift(5)).shift(1)\n",
    "    df_new['return_30'] = ((df['Close'] - df['Close'].shift(21)) / df['Close'].shift(21)).shift(1)\n",
    "    df_new['return_365'] = ((df['Close'] - df['Close'].shift(252)) / df['Close'].shift(252)).shift(1)\n",
    "    df_new['moving_avg_5'] = pd.rolling_mean(df_new['return_1'], window=5)\n",
    "    df_new['moving_avg_30'] = pd.rolling_mean(df_new['return_1'], window=21)\n",
    "    df_new['moving_avg_365'] = pd.rolling_mean(df_new['return_1'], window=252)\n",
    "    \n",
    "    df_new['Log Ret'] = np.log(df['Close']/df['Close'].shift(1))\n",
    "    w = 63 # ~ 1 year\n",
    "    df_new['VolatilityQuater'] = df_new['Log Ret'].rolling(window=w, center=True).std()\n",
    "    \n",
    "    \n",
    "    #RSI\n",
    "    df_new['RSI6']=stock_df['rsi_6']\n",
    "    df_new['VR']=stock_df['vr']\n",
    "    df_new['macd']=stock_df['macd']\n",
    "    \n",
    "    # data from US stock market\n",
    "    \n",
    "    for US_index in US_indecies:\n",
    "        featurename='%s' %USind[US_index]\n",
    "        df_new[featurename]=df_yahoo[featurename]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # the target\n",
    "    df_new['Close'] = df['Close']\n",
    "    df_new=df_new.fillna(method='ffill')\n",
    "    df_new = df_new.dropna(axis=0)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=generate_features(df0050_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Division\n",
    "\n",
    "1. $X,y$: all features except *Close*, 'Close'\n",
    "-  split into [train,val] set\n",
    "- test for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_columns = list(data.drop(['Close'], axis=1).columns)\n",
    "y_column = 'Close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[X_columns]\n",
    "y = data[y_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio =0.2\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:-5], y[:-5],\n",
    "                                                  test_size=val_ratio,\n",
    "                                                  random_state=42)\n",
    "X_test=X[-5:]\n",
    "Y_test=y[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation\n",
    "---\n",
    "1. $\\mathbf{MSE}=\\frac{1}{n}\\sqrt{\\sum{(y_i-y^{prec}_i)^2}}$: small (~0) for good, big for bad (~1)\n",
    "- $\\mathbf{MAE}=\\frac{1}{n}{\\sum{\\left|y_i-y^{prec}_i\\right|}}$: small (~0) for good, big for bad (~1)\n",
    "- $\\mathbf{R^2}$: small (~0) for bad, big for good (~1)\n",
    "  - $\\mathbf{SST=\\text{Sum of tatal error}}=\\sum(y_i-\\bar y)^2$\n",
    "  - $\\mathbf{SSR=\\text{Sum of Residues}}=\\sum(y_i-y^{prec}_i)^2$\n",
    "  - $\\mathbf{R^2=1-\\frac{SSR}{SST}}$, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters Chosen\n",
    "---\n",
    "1. define parameter set, \n",
    "- test \n",
    "- find out best \n",
    "- predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-05, 'eta0': 0.03}\n",
      "MSE: 0.090\n",
      "MAE: 0.220\n",
      "R^2: 0.971\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# First experiment with linear regression\n",
    "\n",
    "# SGD is very sensitive to data with features at different scales. Hence we need to do feature scaling before training.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_val = scaler.transform(X_val)\n",
    "\n",
    "param_grid = {\n",
    "    \"alpha\": [1e-5, 3e-5, 1e-4],\n",
    "    \"eta0\": [0.01, 0.03, 0.1],\n",
    "}\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "lr = SGDRegressor(penalty='l2', n_iter=1000)\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_scaled_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "lr_best = grid_search.best_estimator_\n",
    "# print(grid_search.best_score_)\n",
    "\n",
    "predictions_lr = lr_best.predict(X_scaled_val)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_val, predictions_lr)))\n",
    "print('MAE: {0:.3f}'.format(mean_absolute_error(y_val, predictions_lr)))\n",
    "print('R^2: {0:.3f}'.format(r2_score(y_val, predictions_lr)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.18574336, 81.94858176, 83.36876597, 82.54054246, 81.76222658])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_test = scaler.transform(X_test)\n",
    "lr_best.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 30, 'min_samples_split': 5}\n",
      "MSE: 0.042\n",
      "MAE: 0.180\n",
      "R^2: 0.987\n"
     ]
    }
   ],
   "source": [
    "# Next experiment with random forest\n",
    "\n",
    "param_grid = {\n",
    "    \"max_depth\": [30, 50],\n",
    "    \"min_samples_split\": [5, 10, 20],\n",
    "\n",
    "}\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=1000)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "# print(grid_search.best_score_)\n",
    "\n",
    "rf_best = grid_search.best_estimator_\n",
    "predictions_rf = rf_best.predict(X_val)\n",
    "\n",
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_val, predictions_rf)))\n",
    "print('MAE: {0:.3f}'.format(mean_absolute_error(y_val, predictions_rf)))\n",
    "print('R^2: {0:.3f}'.format(r2_score(y_val, predictions_rf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.36436744, 82.07018865, 83.11011908, 83.26431186, 82.3236982 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.26640095, 82.01824975, 83.08874581, 83.18531409, 82.30270682])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 5}\n",
      "MSE: 0.078\n",
      "MAE: 0.219\n",
      "R^2: 0.975\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.05,0.1,0.2],\n",
    "    \"max_depth\": [5, 10, 15, 20],\n",
    "    \"colsample_bytree\": [0.7,0.8,0.9],\n",
    "}\n",
    "\n",
    "\n",
    "model_xgb = XGBRegressor(learning_rate=0.1, random_state=3, n_estimators=90, subsample=0.8, \n",
    "                      colsample_bytree=0.8, max_depth =15)\n",
    "\n",
    "grid_search = GridSearchCV(model_xgb, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "# print(grid_search.best_score_)\n",
    "\n",
    "xgb_best = grid_search.best_estimator_\n",
    "predictions_xgb = xgb_best.predict(X_val)\n",
    "\n",
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_val, predictions_xgb)))\n",
    "print('MAE: {0:.3f}'.format(mean_absolute_error(y_val, predictions_xgb)))\n",
    "print('R^2: {0:.3f}'.format(r2_score(y_val, predictions_xgb)))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_xgb = XGBRegressor(learning_rate=0.1, random_state=3, n_estimators=90, subsample=0.8, \n",
    "                      colsample_bytree=0.8, max_depth =15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81.85501, 81.95592, 83.12248, 82.64492, 82.26562], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " xgb_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.05426, 82.04069, 83.25623, 82.76489, 82.4588 ], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " xgb_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7, 'learning_rate': 0.1, 'max_depth': 5}\n",
      "MSE: 0.044\n",
      "MAE: 0.152\n",
      "R^2: 0.986\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.05,0.1,0.2],\n",
    "    \"max_depth\": [5, 10, 15, 20],\n",
    "    \"colsample_bytree\": [0.7,0.8,0.9],\n",
    "}\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_scaled_train = scaler.transform(X_train)\n",
    "X_scaled_val = scaler.transform(X_val)\n",
    "\n",
    "\n",
    "model_xgb = XGBRegressor(learning_rate=0.1, random_state=3, n_estimators=90, subsample=0.8, \n",
    "                      colsample_bytree=0.8, max_depth =15)\n",
    "\n",
    "grid_search = GridSearchCV(model_xgb, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "grid_search.fit(X_scaled_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "# print(grid_search.best_score_)\n",
    "\n",
    "xgb_best = grid_search.best_estimator_\n",
    "predictions_xgb = xgb_best.predict(X_scaled_val)\n",
    "\n",
    "print('MSE: {0:.3f}'.format(mean_squared_error(y_val, predictions_xgb)))\n",
    "print('MAE: {0:.3f}'.format(mean_absolute_error(y_val, predictions_xgb)))\n",
    "print('R^2: {0:.3f}'.format(r2_score(y_val, predictions_xgb)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.05426, 82.04069, 83.25623, 82.76489, 82.4588 ], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_test = scaler.transform(X_test)\n",
    "xgb_best.predict(X_scaled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "0px",
    "width": "0px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
